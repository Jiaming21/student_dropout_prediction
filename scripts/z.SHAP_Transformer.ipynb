{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e6ee3-b645-4476-b889-a68713d68fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, matthews_corrcoef, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "import torch.nn.functional as F\n",
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f86110-10f6-471f-89bf-8e7706e05c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_datasets_info = torch.load('/root/autodl-tmp/data/saved_datasets.pth', weights_only=False)\n",
    "loaded_train_dataset = loaded_datasets_info['train_dataset']\n",
    "loaded_val_dataset = loaded_datasets_info['val_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d03144-1801-41ec-a7f1-77202a134861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def extract_features_labels_from_subset(subset):\n",
    "    \n",
    "    loader = DataLoader(subset, batch_size=len(subset))\n",
    "    \n",
    "    for features, labels in loader:\n",
    "        features = features.squeeze(1).numpy()\n",
    "        labels = labels.squeeze(1).numpy()\n",
    "        return features, labels\n",
    "\n",
    "X_train, y_train = extract_features_labels_from_subset(loaded_train_dataset)\n",
    "X_val, y_val = extract_features_labels_from_subset(loaded_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bb8a8-b8d1-4ab0-a3f4-b8c7278dfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deep learning model, here we expand 2nd dimension (channel) to 1 \n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1) \n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82262cd1-10dc-44d6-8458-d73d3aacfea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new = pd.read_csv('/root/autodl-tmp/data/train_data_new.csv') # 644\n",
    "feature_names = train_data_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96123c80-e9a6-4d12-8f24-c312cc9ca6a2",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8af3e-76cd-4a52-a09f-5dee1368fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransformerEncoderClassification, self).__init__()\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=31, nhead=31), \n",
    "            num_layers= 3,\n",
    "        ) \n",
    "        self.fc = nn.Linear(31, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 0, 2)  \n",
    "        x = self.transformer_encoder(x) \n",
    "        x = x.permute(1, 0, 2) \n",
    "        x = x.flatten(1) \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "device = \"cpu\"\n",
    "model = TransformerEncoderClassification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd86c85-7aee-4a0c-81ce-a2270bf537d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/root/autodl-tmp/model_params/Transformer.pth', weights_only=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6dc00-bb87-44d4-9b38-7e1224e0833c",
   "metadata": {},
   "source": [
    "#### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29527fbe-eb6a-4043-b72f-2b610d17ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings(\"ignore\") # this code chunk will have warnings every time constructing the DeepExplainer\n",
    "\n",
    "explainer_transformer = shap.GradientExplainer(model, X_train_tensor) # X_train_tensor as background_data\n",
    "shap_values_transformer = np.sum(explainer_transformer.shap_values(X_val_tensor[:2000]), axis=-1) # 1. shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66c61e-950a-4a75-abb0-7f940aed4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(explainer_transformer.shap_values(X_val_tensor[:10]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a483972a-4278-4027-9a9d-80b14c1c78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_train_tensor)\n",
    "expected_value = predictions.numpy() # 2. base_values (which is just the expected value)\n",
    "\n",
    "shap_values_transformer_reconstructed = shap.Explanation(values=shap_values_transformer.squeeze(1), # construct back to only 2 dim\n",
    "                                             base_values=expected_value, \n",
    "                                             data=X_val_tensor[:2000].squeeze(1), # construct back to only 2 dim\n",
    "                                             feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364391e-342c-4db2-a75e-6457bb5ae4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_transformer_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbea71-9e1e-46a6-b62c-baebe69dc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_values_transformer.squeeze(1).shape)\n",
    "print(expected_value.shape)\n",
    "print(X_val_tensor[:2000].squeeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddbb6f-47cb-4f2c-a8ca-3d63de18400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1_transformer = shap.plots.bar(shap_values_transformer_reconstructed, show=False)\n",
    "plt.savefig('/root/autodl-tmp/SHAP/shap_fig1_transformer.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d96bf-1f10-4161-8d59-e9125cfffb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2_transformer = shap.plots.beeswarm(shap_values_transformer_reconstructed, show=False) \n",
    "plt.savefig('/root/autodl-tmp/SHAP/shap_fig2_transformer.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e88378-7700-4ca3-a39c-7f9cf1199f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303f3de-d768-4922-bbca-38446273c4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1545467-a68c-4495-9311-a914a46d257f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8d46b-333b-4302-9be2-9f9b1e770504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWEdiff",
   "language": "python",
   "name": "swediff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
